{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Gradient descent is an iterative optimization algorithm used to minimize a function by moving in steps in the direction of steepest descent, as defined by the **negative** of the gradient of the function.\n",
    "\n",
    "Recall that the gradient is a fancy word for derivative, or the rate of change of a function. \n",
    "* The gradient is a vector that points in the direction of greatest increase of a function at a given point. \n",
    "\n",
    "Think of performing gradient descent as trying to get to the bottom of a hill from a starting point away from the bottom of the hill. To get to the bottom of the hill the fastest, you take steps in the direction opposite to the direction of steepest ascent, which is the direction of steepest _descent_. \n",
    "\n",
    "<img src=\"images/mountain.jpeg\" width = 800>\n",
    "\n",
    "> Imagine you set a ball rolling down to the bottom of the mountain: the ball will take the path towards the bottom of the hill determined by gradient descent!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note to instructors: \n",
    "\n",
    "1. You might need to review partial derivatives. \n",
    "\n",
    "For a function f(x, y), to take the partial derivative of f(x, y) with respect to x, you differentiate f(x,y) with respect to x while holding y constant. \n",
    "\n",
    "Example: \n",
    "\n",
    "$$f(x, y) = x^2 + y^2$$ \n",
    "\n",
    "$$\\partial f/\\partial x = 2x$$\n",
    "\n",
    "$$\\partial f/\\partial y = 2y$$\n",
    "\n",
    "\n",
    "\n",
    "2. You might need to review the gradient of a function. \n",
    "\n",
    "For a function of two variables f(x,y), the gradient of f(x,y) is defined as a vector with two components: one component is equal to the partial derivative of f(x,y) with respect to x and the second components in equal to the partial derivate of f(x,y) with respect to y. \n",
    "\n",
    "At a point (x, y), the gradient of f(x,y) points in the direction of steepest climb. \n",
    "\n",
    "Example: \n",
    "\n",
    "$$f(x, y) = x^2 + y^2$$ \n",
    "\n",
    "$$\\partial f/\\partial x = 2x$$\n",
    "\n",
    "$$\\partial f/\\partial y = 2y$$\n",
    "\n",
    "$$\\nabla f = \\partial f/\\partial x \\space \\hat x + \\partial f/\\partial y \\space \\hat y$$\n",
    "\n",
    "$$\\nabla f = 2x \\space \\hat x + 2y \\space \\hat y $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# A simple algorithm for Gradient Descent \n",
    "\n",
    "In general, the steps for gradient descent are: \n",
    "\n",
    "1. Initialize a random starting point for the parameter(s) you're trying to optimize. \n",
    "\n",
    "2. Pick a learning rate. This, along with the gradient (or slope) of the cost function at the starting point, determines the step size. *Be careful not to pick too large of a step size!*\n",
    "\n",
    "3. Choose a maximum number of iterations or steps to take. The algorithm will stop after this many steps if a minimum has yet to be found. \n",
    "    \n",
    "4. Calculate the gradient at the current point (initially, the starting point)\n",
    "\n",
    "5. Take a step in the direction opposite to the direction of the gradient. The step size is controlled by the learning rate and the size of the gradient at the current point. \n",
    "\n",
    "6. Repeat the steps until the maximum number of iterations is met. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notes on the learning rate: [link](https://www.jeremyjordan.me/nn-learning-rate/)\n",
    "\n",
    "1. A small learning rate requires many updates before reaching the minimum \n",
    "2. The optimal learning rate quickly converges to the minimum point \n",
    "3. A learning rate that is too large leads to divergent behavior: you may bounce around the minimum!  \n",
    "\n",
    "<img src=\"images/learning_rates.png\" width = 800>\n",
    "\n",
    "_Image from [An introduction to Gradient Descent](https://medium.com/@montjoile/an-introduction-to-gradient-descent-algorithm-34cf3cee752b)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note to instructors: \n",
    "\n",
    "Students may ask how is the learning rate selected. \n",
    "* It is a hyperparameter -- in general, it is a parameter that we tune when performing model fitting. \n",
    "\n",
    "Picking a good learning rate is important, because if we pick a learning rate that is too small, we will need to run the algorithm for a long time until it reaches the minimum, but if we pick a learning rate that is too large, we will take steps to update our parameters which are too large and we may bounce around and never converge on the minimum of our cost function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's go over gradient descent with a simple example. \n",
    "\n",
    "# Gradient descent in 1-d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Find the minimum of $ y = (x + 5)^2 $ starting from $x = 3$ using gradient descent. \n",
    "\n",
    "* Set the learning rate to 0.01. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's visualize the function before applying gradient descent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "x = np.linspace(-15, 10, 500)\n",
    "y = (x + 5)**2\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What happens to the slope of the lines tangential to a function close to the function's minimum? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> The slope is diminishes in magnitude. At the minimum, the slope has a value of 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What can we expect will happen to the step size in the gradient descent algorithm as we reach the minimum? \n",
    "\n",
    "_Remember that the step size is controlled by the learning rate and the size of the gradient or rate of change of the function at the current point._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> Since the step size at a given point is controlled by the learning rate and the value of the gradient (or rate of change, slope) at that point, we can expect the step size to get smaller as we reach the minimum because the slope is getting smaller. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note to instructors: \n",
    "\n",
    "* It's very important for students to grasp this concept. \n",
    "* If you need to spend some extra time here, it's okay. \n",
    "    * Students will be asked a related question later when plotting the cost function vs the number if iterations (See below). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use the technique of gradient descent to find the minimum of this function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# This is our starting point \n",
    "current_x = 3 \n",
    "\n",
    "# This is our learning rate \n",
    "learning_rate = 0.01 \n",
    "\n",
    "# Number of iterations \n",
    "n_iterations = 10000\n",
    "\n",
    "# The gradient of a function of one variable is its derivative! \n",
    "df = lambda x: 2*(x+5)\n",
    " \n",
    "for i in range(n_iterations):\n",
    "    \n",
    "    # store the current value of x in a new variable \n",
    "    previous_x = current_x\n",
    "    \n",
    "    # update the value of x: \n",
    "    current_x = current_x - learning_rate * df(previous_x)\n",
    "    \n",
    "    print('iteration', i+1, \"\\nX value is\", cur_x)\n",
    "\n",
    "print(\"Minimum occurs at\", current_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Does this match what we expect from taking the derivative of f(x) and setting it equal to zero? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> Yes! The minimum of $f(x) = (x + 5)^2$ is at $x = -5$. That's where $\\frac {df}{dx} = 2(x+5) =  0$.  We have recuperated this result! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Gradient descent: Application to Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Next, let's apply gradient descent to a more complicated problem: finding the line of best fit in a simple linear regression problem. \n",
    "\n",
    "Remember that linear regression is a linear approach to modeling the relationship between a dependent variable and one or more independent variables. \n",
    "\n",
    "In the case of **simple** linear regression, where we have one independent variable x, we seek __to find the line of best fit to our data__, defined by:\n",
    "\n",
    "$$ y = mx + b $$\n",
    "\n",
    "Here, m is the slope of the line and b is the y-intercept. \n",
    "\n",
    "Our task is to find the values of m and b that give the minimum error with respect to the data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note to instructors:\n",
    "\n",
    "**Why use gradient descent to find the best parameters?**\n",
    "\n",
    "_We could find a closed-form solution to this problem of finding the best parameters m and b using a linear algebra approach. However, this approach is not computationally feasible when when dealing with large number of observations, as the time complexity of such a solution increases as $O(N^3)$ where N is the number of observations._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's bring in some sample data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "np.random.seed(42) \n",
    "\n",
    "x = 2 * np.random.rand(100,1)\n",
    "y = 4 + 3*x + np.random.randn(100,1)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We seek to find the __line of best fit__ through this data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Cost function for linear regression\n",
    "\n",
    "The cost or loss function is the error in our prediction. We use the mean squared error to compute the cost. \n",
    "\n",
    "Remember that for a line with slope m and y-intercept b, the mean squared error is given by: \n",
    "\n",
    "$$ \\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}\\left( y_i - \\left(mx_i + b\\right)\\right)^2 $$\n",
    "\n",
    "where, for each of the n values of x, $x_i$, we have found the difference between the actual value of y, $y_i$, and the predicted value of $y_i$, squared the difference, and found the mean of the squared difference for every value in x. \n",
    "\n",
    "The cost function $J$, which is equal to the mean squared error, is then:  \n",
    "\n",
    "$$ J(m, b) = \\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}\\left( y_i - \\left(mx_i + b\\right)\\right)^2 $$\n",
    "\n",
    "We seek to find values of m and b that minimize the cost $J(m, b)$ given the data. \n",
    "\n",
    "**We will find the optimal values of m and b using gradient descent.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gradient descent applied to simple linear regression \n",
    "\n",
    "Here are the steps to follow and which you'll implement below: \n",
    "\n",
    "1. Start with random values for m and b. \n",
    "2. Set the learning rate L. (Remember that the learning rate controls how much the values of the parameters change in each iteration of the algorithm). \n",
    "3. Set a maximum number of iterations. \n",
    "\n",
    "4. Calculate the partial derivative of the loss function with respect to m, $\\partial J/\\partial m$, and plug in the current values of m and b to find the value of $\\partial J/\\partial m$ at the starting point. \n",
    "\n",
    "5. Similarly, calculate the partial derivative of the loss function with respect to b, $\\partial J/\\partial b$, and plug in the current values of m and b to find the value of $\\partial J/\\partial b$ at the starting point. \n",
    "\n",
    "6. Update the current values of m and b using the following update rules and the values of the partial derivatives you have just computed:\n",
    "\n",
    "$$ m = m - L  \\frac{\\partial J}{\\partial m} $$\n",
    "\n",
    "\n",
    "$$ b = b - L  \\frac{\\partial J}{\\partial b} $$\n",
    "\n",
    "7. Repeat steps 4 through 6 until all iterations are completed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Before getting started, we provide you with the partial derivatives of the cost function J with respect to m and b: \n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial m} = -\\frac{2}{n}\\sum_{i=1}^{n}\\left( y_i - \\left(mx_i + b\\right)\\right)x_i $$\n",
    "\n",
    "\n",
    "$$ \\frac{\\partial J}{\\partial b} = -\\frac{2}{n}\\sum_{i=1}^{n}\\left( y_i - \\left(mx_i + b\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note to instructors:\n",
    "\n",
    "Students might feel intimidated by the mathematical equations above. You might need to review partial derivatives. \n",
    "\n",
    "Students might need help translating these equations to code. The question below is meant to help them write the sums in code. \n",
    "\n",
    "If x and y are numpy arrays, one can write: \n",
    "\n",
    "$ \\frac{\\partial J}{\\partial m} \\rightarrow $ `(-2/n)*sum(x*(y-y_pred))`\n",
    "\n",
    "$ \\frac{\\partial J}{\\partial b} \\rightarrow $ `(-2/n)*sum(y-y_pred)` \n",
    "\n",
    "where $y_{pred} = mx + b $. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The equation for the cost function for line with slope m and y-intercept b is \n",
    "\n",
    "$$ J(m, b) = \\frac{1}{n}\\sum_{i=1}^{n}\\left( y_i - \\left(mx_i + b\\right)\\right)^2 $$\n",
    "\n",
    "\n",
    "Assuming `x` and `y` are numpy arrays, how would you write this expression in Python? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> `y_pred = m*x + b`\n",
    "\n",
    "> `cost = (1/n)*sum((y - y_pred)**2)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's use gradient descent to find the optimal values for m and b for our example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Start with random values for m and b\n",
    "m, b = np.random.rand(None)\n",
    "\n",
    "# Set the learning rate to 0.001\n",
    "L = None \n",
    "\n",
    "# Set the number of iterations to 10000\n",
    "n_iterations = None \n",
    "\n",
    "# Keep track of the cost after each iteration\n",
    "costs = []\n",
    "\n",
    "for i in range(None):\n",
    "    \n",
    "    # What are the current predicted values of y given\n",
    "    # the current m and b values?\n",
    "    y_pred = None \n",
    "    \n",
    "    # What is the length of y_pred? \n",
    "    n = None \n",
    "    \n",
    "    # What is the error (or cost) of the prediction?\n",
    "    cost = None \n",
    "    \n",
    "    # Add the cost to the list of costs after each iteration\n",
    "    costs.append(cost)\n",
    "    \n",
    "    # Compute the partial derivative of the cost with respect to m and b\n",
    "    # at the current values of m and b\n",
    "    partial_cost_wrt_m = None \n",
    "    partial_cost_wrt_b = None \n",
    "    \n",
    "    # Update the values of the parameters m and b.\n",
    "    m = m - None  \n",
    "    b = b - None \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "# Set a value of the random seed for reproducibility\n",
    "np.random.seed(42) \n",
    "\n",
    "# Start with random values for m and b \n",
    "m, b = np.random.rand(2)\n",
    "\n",
    "# Set the learning rate to 0.001\n",
    "L = 0.001 \n",
    "\n",
    "# Set number of iterations to 10000\n",
    "n_iterations = 10000\n",
    "\n",
    "# Keep track of the cost after each iteration\n",
    "costs = [] \n",
    "\n",
    "for i in range(n_iterations): \n",
    "    \n",
    "    # What are the current predicted values of y given\n",
    "    # the current m and b values?    \n",
    "    y_pred = m*x + b \n",
    "    \n",
    "    # What is the length of y_pred? \n",
    "    n = len(y_pred)\n",
    "    \n",
    "    # What is the error (or cost) of the prediction? \n",
    "    cost = (1/n)*sum((y-y_pred)**2)\n",
    "    \n",
    "    # Add the cost to the list of costs after each iteration\n",
    "    costs.append(cost)\n",
    "        \n",
    "    # Compute the partial derivative of the cost with respect to m and b\n",
    "    # at the current values of m and b\n",
    "    partial_cost_wrt_m = (-2/n)*sum(x*(y-y_pred))\n",
    "    partial_cost_wrt_b = (-2/n)*sum(y-y_pred)\n",
    "    \n",
    "    # Update the values of the parameters m and b.\n",
    "    m = m - L*partial_cost_wrt_m\n",
    "    b = b - L*partial_cost_wrt_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What values did you obtain for m and b? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "m, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Plot the line with the parameters m and b alongside the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = m*x + b\n",
    "plt.scatter(x, y)\n",
    "plt.plot(x, y_pred, 'r')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create a plot of the cost vs the number of iterations. What do you observe happens to the cost as the number of iterations increases?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "plt.plot(range(n_iterations), costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iteration')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> The cost decreases with each subsequent iteration. \n",
    "\n",
    "> As the number of iterations increases, the cost decreases less and less. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Note to instructors: \n",
    "\n",
    "Students should point out that as the number of iterations increases, the reduction in the cost becomes smaller and smaller. \n",
    "\n",
    "Discuss with students why this happens, maybe referring them back to the simple example we completed beforehand: \n",
    "* When we're close to the minimum of a function, the value of the gradient (slope in the case of 1-d) is small. \n",
    "\n",
    "* This means that as we reach the minimum, the steps we take to get there get smaller and smaller, since the size of the step to take to update the parameters is directly proportional to the value of the gradient at that point, which is getting smaller and smaller as it reaches the minimum. \n",
    "\n",
    "Ask students: what modifications could be made to the code such we don't need to complete all 10000 iterations? \n",
    "\n",
    "1. We can set a threshold to stop the algorithm from running: if the decrease in the cost is smaller than some threshold amount, we stop running the algorithm.\n",
    "\n",
    "2. Along with #1, we could increase the learning rate. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sigmoid Function "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's switch gears and discuss the sigmoid function. \n",
    "\n",
    "The sigmoid function f(z) is defined as: \n",
    "\n",
    "$$ \\large f(z) = \\frac{1}{1 + e^{-z}} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create a plot of the sigmoid function for z values ranging from -10 to 10. \n",
    "\n",
    "Set `z = np.linspace(-10, 10, 10000)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sigm = 1. / (1. + np.exp(-z))\n",
    "    return sigm\n",
    "\n",
    "z = np.linspace(-10, 10, 10000)\n",
    "plt.plot(z, sigmoid(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What are the maximum and minimum values of the sigmoid function? \n",
    "\n",
    "What is the value of the sigmoid function when performing logistic regression for classification? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "> The sigmoid function has a minimum value of 0 and a maximum value of 1. \n",
    "\n",
    "> In logistic regression, given a binary target y and features X, we model the logarithmic odds ratio of belonging to the class, $log\\left( \\frac{p}{1-p}\\right)$, with a linear model. \n",
    "\n",
    ">> We use the sigmoid function to squeeze this output to the range 0 to 1, where it can be interpreted as the probability of belonging to the class or not, given the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Summary: \n",
    "\n",
    "1. Gradient descent is an iterative algorithm used to find the minimum of a function. \n",
    "2. Gradient descent can be used in linear regression, where it is used to find the best parameters that minimize the mean squared error.\n",
    "3. The sigmoid function maps numbers ranging from negative infinity to infinity to the range from 0 to 1. "
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
